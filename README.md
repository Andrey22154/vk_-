# Тестовое задание VK. Ранжирование. 

В проекте используются библиотеки XGBoost, LightGBM и CatBoost для обучения моделей ранжирования и оценки их производительности на основе метрик NDCG, pFound и Precision@5.

## Описание файлов
- **model.ipynb**: Основной скрипт, содержащий весь код для подготовки данных, обучения моделей и оценки результатов в виде ноутбука.
- **final_model_1.py**: Финальная модель, которая показала наилучшие результаты.
- **intern_task.parquet**: Данные для задачи.
- **requirements**: зависимости 

## Библиотеки
- NumPy
- Pandas
- Matplotlib
- Seaborn
- scikit-learn
- XGBoost
- LightGBM
- CatBoost

## Процесс работы
1. **Подготовка данных**: Загрузка и очистка данных, удаление неинформативных признаков и сильно коррелирующих пар признаков.
2. **Визуализация данных**: Распределение рангов и количество документов на запрос.
3. **Обучение моделей**:
   - XGBoost Ranker
   - LightGBM с ранжирующей функцией
   - CatBoost Ranker
4. **Оценка моделей**: Использование метрик NDCG@5, pFound@5 и Precision@5 для оценки качества ранжирования.

## Результаты
Модели оцениваются в пяти различных фолдах с использованием GroupKFold, что обеспечивает стабильность и надежность получаемых результатов. Для каждой модели вычисляются средние значения указанных метрик по всем фолдам.
